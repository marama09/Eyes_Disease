{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marama09/Eyes_Disease/blob/main/Amd_of_Final_Eyes_Disease_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63Yty_I-i4v"
      },
      "source": [
        "In this project, I performed a superficial exploratory data analysis, investigated the relationship between diagnostic keyphrases and diagnosed conditions and, based on the latter, implemented some code to sort images of retinal fundi, according to conditions whose symptoms they display.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNLU1EgZ-p_9"
      },
      "outputs": [],
      "source": [
        "# Import everything we need\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from matplotlib import pyplot as plt, image as mpimg\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from collections import Counter\n",
        "import random\n",
        "import glob\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "from sklearn.metrics import classification_report\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers, utils, callbacks\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape, Dropout\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9RnsmzR-qH3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLiJa2go-qOi"
      },
      "outputs": [],
      "source": [
        "# Set up all the paths\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Ocular Disease/ODIR-5K/Training Images/'\n",
        "img_dir = \"/content/drive/MyDrive/Ocular Disease/preprocessed_images\"\n",
        "IMG_DIR = '/content/drive/MyDrive/Ocular Disease/ODIR-5K/Training Images/'\n",
        "file_names = sorted(os.listdir(IMG_DIR))\n",
        "DATA_FOLDER='/content/drive/MyDrive/Ocular Disease/ODIR-5K/Training Images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdlw2WLKUeT"
      },
      "source": [
        "First, let's load our data to a DataFrame and take a look at it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEn3Ub4Fq0Is"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"/content/drive/MyDrive/Ocular Disease/full_df.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGE27YPL-qUO"
      },
      "outputs": [],
      "source": [
        "#Rename columns\n",
        "df.columns = [\"ID\", 'Age', \"Patient Sex\", \"Left_Fundus\", \"Right_Fundus\", \"Left_Diagnostic\", \"Right_Diagnostic\",\"Normal\",\"Diabetes\", \"Glaucoma\", \"Cataract\", \"Amd\", \"Hypertension\", \"Myopia\", \"Other\",\"filepath\",\"labels\", \"target\", \"filename\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O46oUKUye9LT"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utWfBJSUn4r8"
      },
      "outputs": [],
      "source": [
        "print(f\"data shape: {df.shape}\")\n",
        "print(f\"Left-Fundus: {df.Left_Fundus.nunique()}\")\n",
        "print(f\"right fundus: {df.Right_Fundus.nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlnt6znRfAwu"
      },
      "source": [
        "**We have 6392 records, and unique images associated with each record for left and respectively right eye.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpemCtO_e9TW"
      },
      "outputs": [],
      "source": [
        "data_num = df.copy()[['Age', 'Patient Sex', \"Normal\",\"Diabetes\", \"Glaucoma\", \"Cataract\", \"Amd\", \"Hypertension\", \"Myopia\", \"Other\"]]\n",
        "data_num['Patient Sex'] = data_num['Patient Sex'].apply(lambda x:0  if x=='Female' else 1) # we encode sex: Female => 0; Male => 1\n",
        "\n",
        "data_num.hist(figsize=(15,12))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSaLMNOWe9Wv"
      },
      "outputs": [],
      "source": [
        "fig, (ax1) = plt.subplots(1, 1, figsize=(20,5))\n",
        "sns.countplot(ax=ax1, x=\"Age\", data=df)\n",
        "ax1.set_title(\"distribution d'Age  dans  train_df\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0JLWUqLfTw4"
      },
      "source": [
        "We can see a few interesting things here:\n",
        "\n",
        "1) The most prominent age group are people in about their 60s.\n",
        "\n",
        "2) There is slightly more males than females.\n",
        "\n",
        "3) Most patients are not healthy, but healthy patients are the most prevalent of all groups.\n",
        "\n",
        "4) The most prevalent non-healthy group are patients with diabetes, with \"other\" coming right after them.\n",
        "\n",
        "Since this \"other\" category likely lumps many non-related and quite heterogenous conditions, it's going to be more efficient to focus on Amd patients.\n",
        "\n",
        "For now, we will build a model which will discriminate healthy retinas from those displaying signs of diabetes. Later we will test its performance how it performs on the images of retinas with signs of other diseases and see whether we can gain some insight from it.\n",
        "\n",
        "One more thing: let's take a peek at correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnssbjqgfTz8"
      },
      "source": [
        "**Check image data**\n",
        "We check now the image data for completeness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V201cOpge9gY"
      },
      "outputs": [],
      "source": [
        "print(f\"train images: {len(os.listdir('/content/drive/MyDrive/Ocular Disease/ODIR-5K/Training Images'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raq7H6-yfpY8"
      },
      "source": [
        "There are 7000 images in training set and 1000 images in testing set, with half of them for left eye and half of them for right eye.\n",
        "\n",
        "Since there is only one flag for each patology, and we have same record for both eyes for each patient, we will need to infer from the left diagnosys, respectively from right diagnosis, to which eye reffers the flag.\n",
        "\n",
        "For example, for patient with id 0 (Female, age 69), there is a flag 1 for cataract. Looking to the left_diagnosys and right_diagnosys, we observe that only for left_diagnosys we have cataract marked. Consequently, if we want to train a model to recognize cataract, we will only label left eye (image 0_left.png as being with cataract flag 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXLUTcYsfmgD"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "def plot_count(feature, title, df, size=1, show_all=False):\n",
        "    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
        "    total = float(len(df))\n",
        "    if show_all:\n",
        "        g = sns.countplot(df[feature], palette='Set3')\n",
        "        g.set_title(\"{} distribution\".format(title))\n",
        "    else:\n",
        "        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n",
        "        if(size > 2):\n",
        "            plt.xticks(rotation=90, size=8)\n",
        "            for p in ax.patches:\n",
        "                height = p.get_height()\n",
        "                ax.text(p.get_x()+p.get_width()/2.,\n",
        "                        height + 0.2,\n",
        "                        '{:1.2f}%'.format(100*height/total),\n",
        "                        ha=\"center\") \n",
        "        g.set_title(\"Number{}\".format(title))\n",
        "        plt.show()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ3i5QFcfmjI"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Patient Sex\", \"Sex\", df, size=2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUSfCsn8fmmA"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Normal\", \"Normal\", df, size=2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA0kGnsWfmpK"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Diabetes\", \"Diabetes\", df, size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlmZZDBYf6cW"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Glaucoma\", \"Glaucoma\", df, size=2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CuPxQSHf6fa"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Amd\", \"AMD\", df, size=2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSXV3YrygHkr"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Right_Diagnostic\", \"Right eye diagnosys (first 20 values)\", df, size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krKoe5yugHoS"
      },
      "outputs": [],
      "source": [
        "plot_count(\"Left_Diagnostic\", \"Left eye diagnosys (first 20 values)\", df, size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pExGA1gEgVLN"
      },
      "source": [
        "Let's check now frequence of words used in diagnosys for left and right eye, as a wordcloud, to see what are the most frequent words used in such diagnosys.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln7fmEy0gHrL"
      },
      "outputs": [],
      "source": [
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(\n",
        "        background_color='white',\n",
        "        stopwords=stopwords,\n",
        "        max_words=40,\n",
        "        max_font_size=40, \n",
        "        scale=3,\n",
        "        random_state=1,\n",
        "    ).generate(str(data))\n",
        "\n",
        "    fig = plt.figure(1, figsize=(12,10))\n",
        "    plt.axis('off')\n",
        "    if title: \n",
        "        fig.suptitle(title, fontsize=20)\n",
        "        fig.subplots_adjust(top=2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Iu1d1IJaSW"
      },
      "outputs": [],
      "source": [
        "df.loc[(df.Amd==1)]['Left_Diagnostic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qblB817JlRN"
      },
      "outputs": [],
      "source": [
        "df.loc[(df.Amd==1)]['Right_Diagnostic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2oGcf86MKRS"
      },
      "outputs": [],
      "source": [
        "df2= df.iloc[:, 1:7]\n",
        "#df_data2['filepath'] = pd.Series(df_data['filepath'])\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FFXwkVzMa54"
      },
      "outputs": [],
      "source": [
        "df_left_amd = df2[df2['Left_Diagnostic'].str.contains('age-related')]\n",
        "print(len(df_left_amd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQYMddbuMyQs"
      },
      "outputs": [],
      "source": [
        "df_rt_amd = df[df['Right_Diagnostic'].str.contains('age-related')]\n",
        "print(len(df_rt_amd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIeoNktlMazq"
      },
      "outputs": [],
      "source": [
        "# Right diagnosis with 'cataract' keyword\n",
        "df2[df2['Right_Diagnostic'].str.contains('age-related')].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSwmED2oZUP9"
      },
      "outputs": [],
      "source": [
        "df_Amd_filenames = df_left_amd['Left_Fundus'].append(df_rt_amd['Right_Fundus'], ignore_index=True)\n",
        "df_Amd_filenames.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Amd_filenames.shape"
      ],
      "metadata": {
        "id": "CTeDcEjmVNTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A36YkHW2ZdOp"
      },
      "outputs": [],
      "source": [
        "## let's place the Normal data into its own dataframe and print the number of rows\n",
        "df_rt_norm = df[df['Right_Diagnostic'].str.match('normal')]\n",
        "print(len(df_rt_norm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEIRwMEJZdRe"
      },
      "outputs": [],
      "source": [
        "## let's place the Normal data into its own dataframe and print the number of rows\n",
        "\n",
        "df_left_norm = df[df['Left_Diagnostic'].str.match('normal')]\n",
        "print(len(df_left_norm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qOUe08mZdUC"
      },
      "outputs": [],
      "source": [
        "#Combine normal filename data\n",
        "df_norm_filenames = df_left_norm['Left_Fundus'].append(df_rt_norm['Right_Fundus'], ignore_index=True)\n",
        "df_norm_filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Q3LyfHaHMT"
      },
      "outputs": [],
      "source": [
        "df_norm_filenames_random = df_norm_filenames.sample(n = 551)\n",
        "df_norm_filenames_random.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUA3_RoGaHPo"
      },
      "outputs": [],
      "source": [
        "#Add category label to list\n",
        "df_Amd_filenames = pd.DataFrame(df_Amd_filenames, columns = [\"filename\"])\n",
        "\n",
        "# add a new column of '1' to the dataframe\n",
        "df_Amd_filenames[\"label\"] = \"Amd\"\n",
        "\n",
        "df_Amd_filenames.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOpgPNtnaHTB"
      },
      "outputs": [],
      "source": [
        "df_norm_filenames_random = pd.DataFrame(df_norm_filenames_random, columns = [\"filename\"])\n",
        "#df_cat_filenames.set_index(\"filename\", inplace = True)\n",
        "\n",
        "# add a new column of '1' to the dataframe\n",
        "df_norm_filenames_random[\"label\"] = \"normal\"\n",
        "\n",
        "df_norm_filenames_random.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70E_7kjDaHV5"
      },
      "outputs": [],
      "source": [
        "#Append dataframes into a single dataset\n",
        "df_combined = df_Amd_filenames.append(df_norm_filenames_random, ignore_index=True)\n",
        "df_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVORLdXrZdWv"
      },
      "outputs": [],
      "source": [
        "df_combined_random = df_combined.sample(frac=1).reset_index(drop=True)\n",
        "df_combined_random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMpzjqwLgHuC"
      },
      "outputs": [],
      "source": [
        "show_wordcloud(df['Right_Diagnostic'], title = 'Prevalent words in right eye diagnosys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUwtA919gHwn"
      },
      "outputs": [],
      "source": [
        "show_wordcloud(df['Left_Diagnostic'], title = 'Prevalent words in Left eye diagnosys')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JI0OPV6gmRu"
      },
      "source": [
        "We can observe that the words used in diagnosys are quite balanced from the point of view of the two eyes.\n",
        "\n",
        "Let's look now to people with cataract and check what are the associated texts for left and right diagnosys,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8EpMh-bg6i0"
      },
      "outputs": [],
      "source": [
        "# Crude estimation of findings ratio\n",
        "findings = df.iloc[:, -12:-4]\n",
        "totals = findings.sum()\n",
        "totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq9PaiIVg6lu"
      },
      "outputs": [],
      "source": [
        "extended_labels = ['Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'Age related Macular Degeneration', 'Hypertension', 'Pathological Myopia', 'Other abnormalities']\n",
        "plt.pie(totals, labels=extended_labels, startangle=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIK05z82g6oS"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def filter_df(df, letter):\n",
        "    filtered = df.loc[(df[letter] == 1)]\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def display_grid(df, keyword):\n",
        "    rows = 2\n",
        "    cols = 4\n",
        "    nr_images = rows*cols\n",
        "    axes=[]\n",
        "    fig=plt.figure(figsize=(16,8))\n",
        "    filtered = df.loc[df['Left_Diagnostic'].str.contains(keyword)]\n",
        "    \n",
        "    if filtered.shape[0] < nr_images:\n",
        "        nr_images = filtered.shape[0]\n",
        "\n",
        "    for i in range(nr_images):\n",
        "        file_name = filtered.iloc[i]['ID']\n",
        "        file_name = str(file_name) + '_left.jpg'\n",
        "        image = cv2.imread(os.path.join(IMG_DIR, file_name))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        # crop horizontal image for esthetics\n",
        "        if image.shape[1] > image.shape[0]:\n",
        "            w = image.shape[0]\n",
        "            x = (image.shape[1] - w)//2\n",
        "            image = image[:, x:x+w]\n",
        "\n",
        "        axes.append( fig.add_subplot(rows, cols, i+1) )\n",
        "        subplot_title = filtered.iloc[i]['Left_Diagnostic']\n",
        "        # replacing symbol that looks like comma but doesn't show correctly with a regular comma\n",
        "        subplot_title = subplot_title.replace('ï¼Œ', ', ')  \n",
        "        axes[-1].set_title('\\n'.join(wrap(subplot_title,40)))  \n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "        \n",
        "    fig.tight_layout()    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKJO9JCPg6rL"
      },
      "outputs": [],
      "source": [
        "#Normal\n",
        "df_N = filter_df(df, 'Normal')\n",
        "normal = df_N.shape[0]/df.shape[0]*100\n",
        "normal_f = \"{:.2f}\".format(normal)\n",
        "print(f'fraction of healthy patients: {normal_f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR83DBiwg6uS"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from textwrap import wrap\n",
        "display_grid(df_N, 'normal fundus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0khJNlg64d"
      },
      "outputs": [],
      "source": [
        "#Glaucoma\n",
        "df_G = filter_df(df, 'Glaucoma')\n",
        "display_grid(df_G, 'glaucoma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuxHSKU5g670"
      },
      "outputs": [],
      "source": [
        "#Cataract\n",
        "df_C = filter_df(df, 'Cataract')\n",
        "display_grid(df_C, 'cataract')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrreEs1ohbcG"
      },
      "outputs": [],
      "source": [
        "#Diabetes\n",
        "df_D = filter_df(df, 'Diabetes')\n",
        "display_grid(df_D, 'proliferative retinopathy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8PSqzZihbfL"
      },
      "outputs": [],
      "source": [
        "#Age-related Macular Degeneration (AMD)\n",
        "df_A = filter_df(df, 'Amd')\n",
        "display_grid(df_A, 'age-related')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi2FG4eYhbhl"
      },
      "outputs": [],
      "source": [
        "#Hypertension\n",
        "df_H = filter_df(df, 'Hypertension')\n",
        "display_grid(df_H, 'hypertensive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lnz4CJQhbkp"
      },
      "outputs": [],
      "source": [
        "#Pathological Myopia\n",
        "df_M = filter_df(df, 'Myopia')\n",
        "display_grid(df_M, 'myopia')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afi_NHAbGv0P"
      },
      "outputs": [],
      "source": [
        "#Other abnormalities\n",
        "df_O = filter_df(df, 'Other')\n",
        "display_grid(df_O, ' retinal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS6LLwDChsm6"
      },
      "source": [
        "**Randomize our final combined dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm_M5er5FLx0"
      },
      "outputs": [],
      "source": [
        "print(df.loc[(df.Amd==1)].shape)\n",
        "print(df.loc[df.Amd==0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqq-sx3-F_2R"
      },
      "outputs": [],
      "source": [
        "def has_Amd_mentioned(text):\n",
        "    if 'age-related' in text:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZJUmpwBF_8O"
      },
      "outputs": [],
      "source": [
        "df['le_Amd'] = df['Left_Diagnostic'].apply(lambda x: has_Amd_mentioned(x))\n",
        "df['re_Amd'] = df['Right_Diagnostic'].apply(lambda x: has_Amd_mentioned(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw66DW71Hw4B"
      },
      "outputs": [],
      "source": [
        "Amd_le_list = df.loc[(df.Amd==1) & (df.le_Amd==1)]['Left_Fundus'].values\n",
        "Amd_re_list = df.loc[(df.Amd==1) & (df.re_Amd==1)]['Right_Fundus'].values\n",
        "print(len(Amd_le_list), len(Amd_re_list))\n",
        "non_Amd_le_list = df.loc[(df.Amd==0) & (df.Left_Diagnostic==\"normal fundus\")]['Left_Fundus'].sample(266, random_state=314).values\n",
        "non_Amd_re_list = df.loc[(df.Amd==0) & (df.Right_Diagnostic==\"normal fundus\")]['Right_Fundus'].sample(285, random_state=314).values\n",
        "print(len(non_Amd_le_list), len(non_Amd_re_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqyZcAtYHw7U"
      },
      "outputs": [],
      "source": [
        "Amd_list = np.concatenate((Amd_le_list, Amd_re_list), axis = 0)\n",
        "non_Amd_list = np.concatenate((non_Amd_le_list, non_Amd_re_list), axis = 0)\n",
        "print(len(non_Amd_list), len(Amd_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDLTc80dHxBT"
      },
      "outputs": [],
      "source": [
        "def label_image(label):\n",
        "    if label == 1:\n",
        "        return [1,0]\n",
        "    elif label == 0: \n",
        "        return [0,1]\n",
        "\n",
        "def process_data(data_image_list, DATA_FOLDER, is_cataract):\n",
        "    data_df = []\n",
        "    for img in tqdm(data_image_list):\n",
        "        path = os.path.join(DATA_FOLDER,img)\n",
        "        label = label_image(is_cataract)\n",
        "        img = cv.imread(path,cv.IMREAD_COLOR)\n",
        "        img = cv.resize(img, (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
        "        data_df.append([np.array(img),np.array(label)])\n",
        "    shuffle(data_df)\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OwmozBuHkvv"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "import cv2  as cv\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NO_EPOCHS = 50\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD0CUK8TrkkD"
      },
      "outputs": [],
      "source": [
        "Amd_df = process_data(Amd_list, DATA_FOLDER, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiSp4VLRff_o"
      },
      "outputs": [],
      "source": [
        "Amd_no_df = process_data(non_Amd_list, DATA_FOLDER, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d7V_bOvfmTQ"
      },
      "outputs": [],
      "source": [
        "def show_images(data, isTest=False):\n",
        "    f, ax = plt.subplots(5,5, figsize=(15,15))\n",
        "    for i,data in enumerate(data[:25]):\n",
        "        img_num = data[1]\n",
        "        img_data = data[0]\n",
        "        label = np.argmax(img_num)\n",
        "        if label  == 0: \n",
        "            str_label='Cataract'\n",
        "        elif label == 1: \n",
        "            str_label='No Cataract'\n",
        "        if(isTest):\n",
        "            str_label=\"None\"\n",
        "        ax[i//5, i%5].imshow(img_data)\n",
        "        ax[i//5, i%5].axis('off')\n",
        "        ax[i//5, i%5].set_title(\"Label: {}\".format(str_label))\n",
        "    plt.show()\n",
        "\n",
        "show_images(Amd_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9NS98GPHxE8"
      },
      "outputs": [],
      "source": [
        "show_images(Amd_no_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_LMoGB8HxIF"
      },
      "outputs": [],
      "source": [
        "train = Amd_df + Amd_no_df\n",
        "shuffle(train)\n",
        "show_images(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJSEsG69HxLP"
      },
      "outputs": [],
      "source": [
        "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "y = np.array([i[1] for i in train])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sWeP1YBP_Op"
      },
      "source": [
        "#Base line "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXL8qMXuGAFV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eVHoEThLG-S"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(InputLayer(input_shape=X_train.shape[1:]))\n",
        "cnn_model.add(Conv2D(filters=10, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling2D())\n",
        "cnn_model.add(GlobalAveragePooling2D())\n",
        "cnn_model.add(Dense(20, activation='relu'))\n",
        "cnn_model.add(Dense(2, activation='sigmoid')) \n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "cnn_model.fit(X_train, y_train,\n",
        "                  batch_size=32,\n",
        "                  epochs=20,\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLcnjscVLHBW"
      },
      "outputs": [],
      "source": [
        "score = cnn_model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1pu2X4FRWnN"
      },
      "source": [
        "#Resnet50 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T99oK_0hLHEN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "model = Sequential()\n",
        "model.add(ResNet50(include_top=False, pooling='max', weights='imagenet'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "# ResNet-50 model is already trained, should not be trained\n",
        "model.layers[0].trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSuTLf2JLHHF"
      },
      "outputs": [],
      "source": [
        "#opt = tfa.optimizers.LazyAdam()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.025)\n",
        "model.compile(optimizer='sgd', loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLnv9E3zLHKN"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeY_SLseLHNF"
      },
      "outputs": [],
      "source": [
        "train_model = model.fit(X_train, y_train,\n",
        "                  batch_size=BATCH_SIZE,\n",
        "                  epochs=NO_EPOCHS,\n",
        "                  verbose=1,\n",
        "                   validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKwwOaupSJdA"
      },
      "source": [
        "#Validation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVv2i0UcLHP8"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_and_loss(train_model):\n",
        "    hist = train_model.history\n",
        "    acc = hist['accuracy']\n",
        "    val_acc = hist['val_accuracy']\n",
        "    loss = hist['loss']\n",
        "    val_loss = hist['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
        "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
        "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "    ax[0].set_title('Training and validation accuracy')\n",
        "    ax[0].legend()\n",
        "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
        "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    ax[1].set_title('Training and validation loss')\n",
        "    ax[1].legend()\n",
        "    plt.show()\n",
        "plot_accuracy_and_loss(train_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJiaRxokSQWq"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ACsm_drSQZu"
      },
      "outputs": [],
      "source": [
        "#get the predictions for the test data\n",
        "#y_pred = np.argmax(model.predict(X_val,axis=-1))\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "#get the indices to be plotted\n",
        "#y_true = np.argmax(y_val,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U0K6DtSSQcn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "print('Classification Report')\n",
        "target_names = ['Amd', 'Normal']\n",
        "print(classification_report(y_val, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YaP-E58jAZB"
      },
      "source": [
        "**Split our dataframe into test, train, validation dataframes**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho8usnB3iRay"
      },
      "outputs": [],
      "source": [
        "df_train = df_combined_random.sample(frac=0.8,random_state=42)\n",
        "df_train.reset_index(drop=True)\n",
        "\n",
        "# exclude the 80% that was already chosen, the remaining 20% will go into testing\n",
        "df_test = df_combined_random.drop(df_train.index)\n",
        "df_test.reset_index(drop=True)\n",
        "\n",
        "print(len(df_combined_random))\n",
        "print(len(df_train))\n",
        "print(len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcTwz9UiRgA"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            rescale=1./255.,\n",
        "            validation_split=0.20,\n",
        "            rotation_range=90,\n",
        "#            width_shift_range=0.2,\n",
        "#            height_shift_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            shear_range=0.2,\n",
        "            brightness_range=[0.3,1]    \n",
        "#            zoom_range=0.2\n",
        "            )\n",
        "\n",
        "## for testing we don't want to do too much augmentation, we'll just scale it.\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen"
      ],
      "metadata": {
        "id": "nVrRxI-Gpzz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avfd6k-uiIR7"
      },
      "outputs": [],
      "source": [
        "#Convert row objects to string type\n",
        "df_train['label'] = df_train['label'].astype(str)\n",
        "df_test['label'] = df_test['label'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82QXMafAjXED"
      },
      "source": [
        "**Create test, train and validation image data generators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-AlbesVjU27"
      },
      "outputs": [],
      "source": [
        "#image size\n",
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWUoO8TsjU5_"
      },
      "outputs": [],
      "source": [
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "dataframe=df_train,\n",
        "directory=DATA_FOLDER,\n",
        "x_col=\"filename\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(img_size,img_size))\n",
        "\n",
        "## validation set is created from the training set, \n",
        "## we set it at 20% of the training data in the previous code  -- need to \n",
        "\n",
        "valid_generator=train_datagen.flow_from_dataframe(\n",
        "dataframe=df_train,\n",
        "directory=DATA_FOLDER,\n",
        "x_col=\"filename\",\n",
        "y_col=\"label\",\n",
        "subset=\"validation\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(img_size,img_size))\n",
        "\n",
        "\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=df_test,\n",
        "directory=DATA_FOLDER,\n",
        "x_col=\"filename\",\n",
        "y_col=\"label\",\n",
        "batch_size=32,\n",
        "#seed=42,\n",
        "shuffle=False,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(img_size,img_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNP8IvAtjU83"
      },
      "outputs": [],
      "source": [
        "## models to import\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4xOtOEWjmtG"
      },
      "outputs": [],
      "source": [
        "# get VGG16 base model\n",
        "vgg16 = keras.applications.vgg16.VGG16(input_shape=(224, 224, 3),\n",
        "                                       weights='imagenet',\n",
        "                                       include_top=False)\n",
        "\n",
        "# add new dense layers at the top\n",
        "x = keras.layers.Flatten()(vgg16.output)\n",
        "x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "## remember we are using 2 outputs only\n",
        "predictions = keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# define and compile model\n",
        "model = keras.Model(inputs=vgg16.inputs, outputs=predictions)\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnljIzDBjyPG"
      },
      "source": [
        "**Create check point and early stop**\n",
        "<br>\n",
        "A check point allows us to monitor the acuraccy and perform some task, in this case we will save the model as a file.\n",
        "\n",
        "The early stop will monitor accuracy for a 'patience' parameter and if there is no improvement it will stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCK7dRLtjn8g"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", \n",
        "                             monitor='val_accuracy', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=False, \n",
        "                             mode='auto', \n",
        "                             period=1)\n",
        "\n",
        "early = EarlyStopping(monitor='val_accuracy', \n",
        "                      min_delta=0, \n",
        "                      patience=3, \n",
        "                      verbose=1, \n",
        "                      mode='auto')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfYXl-JtZ7be"
      },
      "source": [
        "**Constants for our training run**\n",
        "<br>\n",
        "SPE is 'steps per epoch'\n",
        "<br>\n",
        "n_val_steps is 'number of validation steps'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3d2-UtrjoIs"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "n_spe = train_generator.samples // batch_size\n",
        "n_val_steps = valid_generator.samples // batch_size\n",
        "n_epochs = 50\n",
        "print(n_spe,n_val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTAG773cjmwb"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(train_generator,\n",
        "                        steps_per_epoch=n_spe,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=n_val_steps,\n",
        "                        epochs=n_epochs,\n",
        "                        shuffle=True,\n",
        "                        workers=5,\n",
        "                        use_multiprocessing=True,\n",
        "                        callbacks=[checkpoint,early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FhnruR6j-Zf"
      },
      "outputs": [],
      "source": [
        "#Load our saved model\n",
        "#from keras.models import load_model\n",
        "#model.save(\"./vgg16_1.h5\", save_format=\"h5\")\n",
        "#model = load_model('./vgg16_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cUJQOmbj-c0"
      },
      "outputs": [],
      "source": [
        "#Plot accuracy versus loss\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Training loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qQ1P7sUj-fq"
      },
      "outputs": [],
      "source": [
        "test_generator.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c5Xjwohj-i2"
      },
      "outputs": [],
      "source": [
        "pred = model.predict_generator(test_generator,verbose=1,steps=test_generator.samples/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wejZrnwJj-lq"
      },
      "outputs": [],
      "source": [
        "#Prediction raw data\n",
        "## let's get the first 10 rows\n",
        "print(pred[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWHBf0WBkTJl"
      },
      "source": [
        "#Convert raw prediction data\n",
        "Let's convert the raw data into something more friendly, 1's and 0's. Argmax will do this for us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCiT-WkrkU-w"
      },
      "outputs": [],
      "source": [
        "predicted_class_idx=np.argmax(pred,axis=1)\n",
        "## print the same 10 rows\n",
        "print(predicted_class_idx[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdtE0vEWkVBk"
      },
      "outputs": [],
      "source": [
        "print(len(predicted_class_idx))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epOeg99JkjHC"
      },
      "source": [
        "#Evaluate our model's accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKIbih3vkVER"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_generator,use_multiprocessing=True,workers=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQhnKhCYkotP"
      },
      "source": [
        "#Convert one-hot category labels to text labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBjSGNo4kVHE"
      },
      "outputs": [],
      "source": [
        "valid_generator.class_indices.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeMVxGf1kVJ6"
      },
      "outputs": [],
      "source": [
        "valid_labels = dict((value,key) for key,value in valid_generator.class_indices.items())\n",
        "pred_labels = [valid_labels[key] for key in predicted_class_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqxPkDCskvhM"
      },
      "outputs": [],
      "source": [
        "pred_labels[1:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEz76RZWk4xx"
      },
      "source": [
        "#Build a new dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J51WU6kOkvm2"
      },
      "outputs": [],
      "source": [
        "filenames = test_generator.filenames\n",
        "prediction_df = pd.DataFrame({'Filename': filenames,'Prediction': pred_labels})\n",
        "prediction_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmgJx_ptk-fo"
      },
      "source": [
        "#Verify prediction dataframe results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KD4L6JFkvpt"
      },
      "outputs": [],
      "source": [
        "prediction_df.iloc[35]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJudh9oqk7bs"
      },
      "outputs": [],
      "source": [
        "print(test_generator.filenames[35])\n",
        "print(test_generator.labels[35])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q40AHWeLlHlw"
      },
      "source": [
        "#Correct vs. Incorrect list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9VAGyElk7eh"
      },
      "outputs": [],
      "source": [
        "test_file_names=test_generator.filenames  # sequential list of name of test files of each sample\n",
        "test_labels=test_generator.labels # is a sequential list  of test labels for each image sample\n",
        "class_dict= test_generator.class_indices # a dictionary where key is the class name and value is the label for the class\n",
        "\n",
        "print (class_dict) # have a look at the dictionary\n",
        "new_dict={} \n",
        "\n",
        "for key in class_dict: # set key in new_dict to value in class_dict and value in new_dict to key in class_dict\n",
        "    value = class_dict[key]\n",
        "    new_dict[value] = key\n",
        "\n",
        "print('  RESULT  PREDICT      TRUE CLASS       FILENAME ' ) # adjust spacing based on your class names\n",
        "\n",
        "for i, p in enumerate(pred):\n",
        "    pred_index=np.argmax(p) # get the index that has the highest probability\n",
        "    pred_class=new_dict[pred_index]  # find the predicted class based on the index\n",
        "    true_class=new_dict[test_labels[i]] # use the test label to get the true class of the test file\n",
        "    file=test_file_names[i]\n",
        "    \n",
        "    if true_class == pred_class:\n",
        "        result = \"Correct\"\n",
        "    else:\n",
        "        result = \"Wrong  \"\n",
        "    \n",
        "    \n",
        "    print(f' {result}   {pred_class}    {true_class}      {file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u68nucJslQoG"
      },
      "source": [
        "#Another approach to generator data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNWrqYjVk7ha"
      },
      "outputs": [],
      "source": [
        "x_test, y_test = test_generator.next()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgM_8wxdk7kB"
      },
      "outputs": [],
      "source": [
        "print(len(x_test))\n",
        "print(len(y_test))\n",
        "\n",
        "\n",
        "## compare this length to our prediction data and notice the difference.  \n",
        "\n",
        "print(len(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESN_I6-Yk7m4"
      },
      "outputs": [],
      "source": [
        "loss,accuracy = model.evaluate(x_test,y_test)\n",
        "print(\"loss:\",loss)\n",
        "print(\"Accuracy:\",accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dsFZ-4NlbAs"
      },
      "source": [
        "#Prediction vs Test image grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08kDu3wik7pu"
      },
      "outputs": [],
      "source": [
        "test_image_data, test_labels = test_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8XXNK6ok7sa"
      },
      "outputs": [],
      "source": [
        "print(test_image_data.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSuxztihljL6"
      },
      "outputs": [],
      "source": [
        "z = 0\n",
        "#test filename\n",
        "\n",
        "test_file_names=test_generator.filenames[z]\n",
        "print(test_file_names)\n",
        "\n",
        "test_labels_example=test_generator.labels[z]\n",
        "print(test_labels_example)\n",
        "\n",
        "pred_labels[z]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEan6PzUln2B"
      },
      "source": [
        "#Convert test labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_4h5y6mljO7"
      },
      "outputs": [],
      "source": [
        "test_labels[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpLxfSAhljRi"
      },
      "outputs": [],
      "source": [
        "test_class_idx=np.argmax(test_labels,axis=1)\n",
        "#test_class_idx[4]\n",
        "test_class_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQ4lMUQlxMd"
      },
      "source": [
        "#Plot our comparison grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_0WAZiSljUZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "for i in range(18):\n",
        "    sample = random.choice(range(test_generator.samples))\n",
        "#    print(str(sample))\n",
        "    img = test_generator.filenames[sample]\n",
        "    image = cv2.imread(os.path.join(DATA_FOLDER, img))\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    category = test_generator.labels[sample]\n",
        "    pred_category = pred_labels[sample]\n",
        "\n",
        "#    sample = random.choice(range(0,test_generator.samples))    \n",
        "#    image = test_image_data[sample]\n",
        "#    category = test_class_idx[sample]\n",
        "#    pred_category = pred_labels[sample]\n",
        "           \n",
        "    \n",
        "    if category== 1:\n",
        "        label = \"Normal\"\n",
        "    else:\n",
        "        label = \"Amd\"\n",
        "        \n",
        "    if pred_category== \"normal\":\n",
        "        pred_label = \"Normal\"\n",
        "    else:\n",
        "        pred_label = \"Amd\"\n",
        "\n",
        "    if label == pred_label:\n",
        "        result = \"Correct\"\n",
        "    else:\n",
        "        result = \"Wrong\"\n",
        "\n",
        "        \n",
        "    plt.subplot(3,6,i+1)\n",
        "    plt.imshow(image_rgb, interpolation='nearest')\n",
        "    plt.xlabel(\"Actual:{}\\nPrediction:{}\\nResult:{}\".format(label,pred_label,result))\n",
        "plt.tight_layout() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yt1ndwKl8A_"
      },
      "source": [
        "#Classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCjqrK3jljXA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "print('Classification Report')\n",
        "target_names = ['Amd', 'Normal']\n",
        "print(classification_report(test_generator.classes, predicted_class_idx, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olu9bMnUmBg_"
      },
      "source": [
        "#Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYEEF6Jdl_g4"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_generator.labels, predicted_class_idx)\n",
        "print('Confusion Matrix')\n",
        "cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDphIYnamJTq"
      },
      "source": [
        "#Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzN9LSWYl_jt"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB4eTtGCl_m1"
      },
      "outputs": [],
      "source": [
        "cm_plot_labels = ['Amd','normal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLSP3XRfmUQg"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Amd of Final Eyes Disease Classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}